# source code

# build

doc/build.md

# run

[prithivMLmods/Llama-Deepsync-1B-GGUF](https://huggingface.co/prithivMLmods/Llama-Deepsync-1B-GGUF)

./build/bin/llama-cli -m models/Llama-Deepsync-1B.Q4_K_M.gguf -p "what's your name"

# modify

## show block process entry

## train

## Specific parameter

cd /home/xunchan/Workspace/llama.xunchan/gguf-py/examples

python reader.py  /home/xunchan/Workspace/llama.xunchan/models/Llama-Deepsync-1B.Q4_K_M.gguf

or

show in [huggingface](https://huggingface.co/) frontend

## general.architecture

llama

## llama

### llama.block_count

### llama.context_length

### llama.embedding_length

### llama.feed_forward_length

### 

#### block

# Modify code

## Find the llama block code process location

## Write it precifily

# doc

# done